\documentclass[11pt]{article}

\usepackage[a4paper,fancysections,titlepage]{polytechnique}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{blindtext}
\usepackage[hidelinks]{hyperref}
\usepackage{amsmath,amssymb}
\usepackage{pdfpages}
\usepackage{setspace}

\setlength{\parskip}{1em}
\setstretch{1}

\newcommand{\code}[1]{%
    \mbox{\ttfamily%
        \detokenize{#1}%
    }%
}

\newcommand{\resultat}[1]{%
    \quad \rightsquigarrow \quad #1%
}

% \logo{delos_logo.jpeg}
\author{Nathan Duboisset - Rom\'eo Nazaret}
\date{\today}
\title{Detection of eye look poisition with computer vision}
\subtitle{Projet CSC51073 -- 2025}

\begin{document}

\maketitle

\tableofcontents

\newpage
\section{Introduction}
\subsection{Context and motivation}
Computer vision and image processing are now widely used in many applications. Eye tracking and pupil detection have become important tools with practical uses.

Pupil detection systems have several useful applications. They can be used as anti-cheating systems in exams by monitoring where students look. They also help people with severe disabilities communicate through eye movements when they cannot move other parts of their body. These applications show why we need accurate and real-time pupil detection methods.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{example_context.png}
    \caption{Example of pupil detection application}
    \label{fig:example_context}
\end{figure}

\subsection{Problem}

Detecting the position of the eyes is a difficult task because the eyes can be occluded by other objects, the eyes can be closed, they can be looking in different directions, etc.
Also there is a lot of technical problem : how to have precise description of the eyes position regardless of head position, quality of the video, number of images per second, etc.

We must be able to adapt to all these different situations while keeping a good precision and a low latency, thus using fast enough solutions.


\subsection{Project goals}
Our goal is to detect the position of the eyes in a video with a good precision and a low latency. We will use a computer vision algorithm to detect the eyes position. We will also try to use a machine learning algorithm to detect the eyes position.
As we will use the webcam of our computer, we will have a difficult enough problem, as the quality of the video is not always good.

\newpage
\section{State of the art}
\subsection{AFIG 2007}

\subsection{MediaPipe Face Mesh algorithms}


\subsection{Other approaches}

\newpage
\section{Implemented method}
\subsection{General architecture}

We chose to focus first on the detection of the eyes gaze position rather than detecting the position of the objects themselves as these tools are already widely used and have a lot of research, and good and fast implementations. Thus we used mediapipe and took the computing from there.

\subsection{Gathering of positions data}

We use mediapipe to gather the positions of the eyes and the face. We use the face mesh algorithm to get the positions of the eyes and the face. We use the iris landmarks to get the positions of the pupils.
We also use mediapipe to gather the position of the pupils on the face.(TODO : pupil position detection)
Using this, we compute where should be the position of the middle of the eyeballs, and thus obtain two vectors supposed to be the direction of the eye gaze.

\subsection{Algorithme de d\'etection pupillaire}
% [TODO: D\'etailler l'algorithme morphologique bas\'e sur Cm et Cc]
\subsubsection{Coefficient morphologique $C_m$}
% [TODO: Expliquer le calcul de Cm]

\subsubsection{Coefficient colorim\'etrique $C_c$}
% [TODO: Expliquer le calcul de Cc]

\subsubsection{Proc\'edure en deux passes}
% [TODO: D\'ecrire pass1 (balayage grossier) et pass2 (raffinement)]

\subsection{Pr\'e-traitement et post-traitement}
% [TODO: D\'ecrire les \'etapes de normalisation, recadrage, filtrage]

\newpage
\section{Impl\'ementation}
\subsection{Organisation du code}
% [TODO: D\'ecrire la structure du projet: python_vision/, src/, data/]

\subsection{Module Python}
% [TODO: D\'etailler les scripts principaux: implementationAlgo2007.py, etc.]

\subsection{Biblioth\`eque C++}
% [TODO: Pr\'esenter EyeToolKit et son r\^ole]

\subsection{Acquisition et journalisation des donn\'ees}
% [TODO: Expliquer le syst\`eme de capture et de logging (csv_log.py, data/)]

\newpage
\section{R\'esultats}
\subsection{Protocole exp\'erimental}
% [TODO: D\'ecrire le protocole de test: donn\'ees utilis\'ees, m\'etriques]

\subsection{Performances quantitatives}
% [TODO: Pr\'esenter les r\'esultats chiffr\'es: pr\'ecision, latence, taux de d\'etection]

\subsection{Analyse qualitative}
% [TODO: Discuter des cas de r\'eussite et d'\'echec, visualisations]

\subsection{Comparaison avec l'\'etat de l'art}
% [TODO: Comparer avec d'autres m\'ethodes si possible]

\newpage
\section{Discussion}
\subsection{Forces de l'approche}
% [TODO: Identifier les points forts de la m\'ethode]

\subsection{Limites et d\'efis}
% [TODO: Discuter des limites: variations inter-individuelles, conditions lumineuses, etc.]

\subsection{Am\'eliorations possibles}
% [TODO: Proposer des pistes d'am\'elioration]

\newpage
\section{Conclusion}
% [TODO: R\'esumer le projet, les r\'esultats et les perspectives]

\newpage
\appendix
\section*{R\'ef\'erences}
\addcontentsline{toc}{section}{R\'ef\'erences}
\begin{thebibliography}{9}
\bibitem{afig2007}
B.~Raynal.
\newblock \emph{Reconnaissance de la pupille par morphologie math\'ematique}.
\newblock Actes de l'AFIG, 2007.
\end{thebibliography}

\end{document}
